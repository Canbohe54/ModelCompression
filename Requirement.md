# 需求文档

## 1. 总体功能需求
&emsp;&emsp;建立并长期维护一个模型压缩github工具库，提供剪枝、量化、知识蒸馏、低秩分解等模型压缩方法，用户可通过此软件压缩自己指定的模型，以达到他们期望的模型压缩率和精度损失率。

## 2. demo版本
&emsp;&emsp;程序实现剪枝、量化、知识蒸馏三种模型压缩方法，用户下载源码后，若要压缩模型，需提供以下信息：
1. 压缩前模型
2. 压缩方法
<p>&emsp;&emsp;该版本基本是以“先跑起来再说”的前提编写的，程序将会内置一套默认的模型压缩参数，且暂时无法修改，用户只能通过此版本大致了解某种压缩方法可能达到的效果</p>
<p>&emsp;&emsp;&emsp;&emsp;例如：通过此版本，用户可得知非结构化剪枝仅能减少运算时间，而无法减少内存</p>

### 信息展示
<p>&emsp;&emsp;向用户展示压缩前后的模型参数、内存大小和计算量，准确率；展示压缩造成的压缩率和准确率丢失率</p>

## 3. 评估需求

## 4. 各（规模）类模型适用压缩方法
### 4.1 线性模型
### 4.2 卷积神经网络
### 4.3 不同应用领域的模型

## 5. 各（规模）模型压缩参数
疑点：模型压缩有没有所谓“最优参数”？
“最优参数”是针对模型的，与压缩需求无关的，还是还与压缩需求有关？笔者更倾向于调出该压缩方法的最优参数，再通过多个方法横向比较，向用户给出最优压缩中最符合其需求的模型。

## 6. 压缩方法的结合
### 6.1 结构化剪枝+蒸馏

## 5+6 疑点
压缩方法结合后，模型压缩的最优参数是否会发生变化？（应该是会的），结合后如何调节两种方法的参数？

## 7. 以用户需求为导向的模型压缩方法
### 7.1 用户需求类型（用户偏好）
### 7.2 压缩方法的偏好
### 7.3 如何将方法偏好向用户偏好拟合
